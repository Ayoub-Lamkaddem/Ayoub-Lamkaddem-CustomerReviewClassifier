import streamlit as st
import joblib
import os
import torch
from transformers import AutoTokenizer, BertForSequenceClassification, pipeline, XLNetForSequenceClassification, XLNetTokenizer

# Add custom page configuration
st.set_page_config(
    page_title="Sentiment Analysis App ğŸ“Š", 
    page_icon="ğŸ”", 
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for improved styling
st.markdown("""
    <style>
    .big-font {
        font-size:20px !important;
        color: #2C3E50;
    }
    .stButton>button {
        background-color: #3498DB;
        color: white;
        border-radius: 10px;
    }
    .stTextArea>div>div>textarea {
        border: 2px solid #3498DB;
        border-radius: 10px;
    }
    </style>
    """, unsafe_allow_html=True)

# Fonction pour charger le modÃ¨le et les dÃ©pendances
def load_model(model_name):
    try:
        if "SVM" in model_name:
            # Load SVM model
            model = joblib.load('SVM/svm_model.pkl')
            vectorizer = joblib.load('SVM/tfidf_vectorizer.pkl')
            # No label encoder needed for SVM as mentioned
            return model, vectorizer, None
        elif "RÃ©gression" in model_name:
            # Existing Logistic Regression model loading
            model = joblib.load('Logistic Regression/logreg_model.pkl')
            vectorizer = joblib.load('Logistic Regression/tfidf_vectorizer.pkl')
            label_encoder = joblib.load('Logistic Regression/label_encoder.pkl')
            return model, vectorizer, label_encoder
        elif "BERT" in model_name:
            try:
                # Chemin du modÃ¨le BERT
                path = "fine_tuned_BERT"
                
                # VÃ©rifier l'existence du dossier
                if not os.path.exists(path):
                    raise ValueError(f"Le dossier {path} n'existe pas")
                
                # Charger le modÃ¨le et le tokenizer
                model = BertForSequenceClassification.from_pretrained(path, num_labels=3)
                tokenizer = AutoTokenizer.from_pretrained(path)
                
                # Mettre le modÃ¨le en mode Ã©valuation
                model.eval()
                
                return model, tokenizer, None
            
            except Exception as e:
                st.error(f"Erreur lors du chargement du modÃ¨le BERT : {str(e)}")
                # Afficher le contenu du dossier pour le dÃ©bogage
                st.write("Contenu du dossier fine_tuned_BERT:")
                st.write(os.listdir("fine_tuned_BERT"))
                return None, None, None
        elif "XLNET" in model_name:
            try:
                # Chemin du modÃ¨le XLNet
                path = "fine_tuned_XLNET"
                
                # VÃ©rifier l'existence du dossier
                if not os.path.exists(path):
                    raise ValueError(f"Le dossier {path} n'existe pas")
                
                # Charger le modÃ¨le et le tokenizer
                model = XLNetForSequenceClassification.from_pretrained(path, num_labels=3)
                tokenizer = XLNetTokenizer.from_pretrained(path)
                
                # Mettre le modÃ¨le en mode Ã©valuation
                model.eval()
                
                return model, tokenizer, None
            
            except Exception as e:
                st.error(f"Erreur lors du chargement du modÃ¨le XLNet : {str(e)}")
                # Afficher le contenu du dossier pour le dÃ©bogage
                st.write("Contenu du dossier fine_tuned_XLNET:")
                st.write(os.listdir("fine_tuned_XLNET"))
                return None, None, None
        else:
            st.error(f"ModÃ¨le non pris en charge : {model_name}")
            return None, None, None
    except Exception as e:
        st.error(f"Erreur lors du chargement du modÃ¨le : {e}")
        return None, None, None

# Fonction pour effectuer la prÃ©diction
def predict_sentiment(text, model, vectorizer, label_encoder):
    if not text.strip():
        return "Erreur : Le champ de texte est vide. "
    try:
        # Gestion spÃ©cifique pour le modÃ¨le BERT et XLNet
        if isinstance(model, (BertForSequenceClassification, XLNetForSequenceClassification)):
            # Tokeniser et prÃ©parer l'entrÃ©e pour BERT/XLNet
            inputs = vectorizer(text, return_tensors="pt", padding=True, truncation=True, max_length=512)
            
            # Faire la prÃ©diction
            with torch.no_grad():
                outputs = model(**inputs)
                predictions = torch.softmax(outputs.logits, dim=1)
                predicted_class = torch.argmax(predictions, dim=1).item()
            
            # Mapper les classes
            sentiment_labels = ['negative', 'neutral', 'positive']
            predicted_label = sentiment_labels[predicted_class]
            
            # Mapping des sentiments
            sentiment_map = {
                "positive": ("ğŸŒŸ Commentaire positif ! ğŸ‰ Le commentaire est trÃ¨s enthousiaste et encourageant ğŸš€", "success"),
                "negative": ("ğŸ˜” Sentiment nÃ©gatif ! ğŸš« Le commentaire exprime de la frustration ou de l'insatisfaction ğŸ’¥", "error"), 
                "neutral": ("ğŸ˜ Commentaire neutre ğŸ¤·â€â™€ï¸ Aucune Ã©motion forte n'est exprimÃ©e ", "warning")
            }
            
            message, color_type = sentiment_map[predicted_label]
            
            # Utiliser la mÃ©thode de message colorÃ© appropriÃ©e
            if color_type == "success":
                st.success(message)
            elif color_type == "error":
                st.error(message)
            elif color_type == "warning":
                st.warning(message)
            
            return message
        
        # Code existant pour SVM et RÃ©gression Logistique
        # Vectorisation du texte
        text_tfidf = vectorizer.transform([text])
        # PrÃ©diction
        predicted_rating = model.predict(text_tfidf)
        
        # DÃ©codage de la prÃ©diction
        if label_encoder:
            predicted_rating_label = label_encoder.inverse_transform(predicted_rating)
        else:
            # Pour SVM, essayons de convertir directement
            if predicted_rating[0] in [0, 1, 2]:
                predicted_rating_label = ['negative', 'neutral', 'positive'][predicted_rating[0]]
            else:
                predicted_rating_label = [str(predicted_rating[0])]
        
        # Mapping flexible pour gÃ©rer diffÃ©rents formats de labels
        sentiment_map = {
            "positive": ("ğŸŒŸ Commentaire positif ! ğŸ‰ Le commentaire est trÃ¨s enthousiaste et encourageant ğŸš€", "success"),
            "negative": ("ğŸ˜” Sentiment nÃ©gatif ! ğŸš« Le commentaire exprime de la frustration ou de l'insatisfaction ğŸ’¥", "error"), 
            "neutral": ("ğŸ˜ Commentaire neutre ğŸ¤·â€â™€ï¸ Aucune Ã©motion forte n'est exprimÃ©e ", "warning")
        }
        
        # Convertir en minuscules pour correspondance insensible Ã  la casse
        label = str(predicted_rating_label[0]).lower()
        
        # VÃ©rifier si le label existe dans le mapping
        if label in sentiment_map:
            message, color_type = sentiment_map[label]
            
            # Utiliser la mÃ©thode de message colorÃ© appropriÃ©e
            if color_type == "success":
                st.success(message)
            elif color_type == "error":
                st.error(message)
            elif color_type == "warning":
                st.warning(message)
            
            return message
        else:
            # Si le label n'est pas dans le mapping, afficher un message gÃ©nÃ©rique
            st.info(f"Sentiment dÃ©tectÃ© : {label}")
            return f"Sentiment dÃ©tectÃ© : {label}"
    except Exception as e:
        return f"Erreur lors de la prÃ©diction : {e}"

# Interface Streamlit
st.title("ğŸŒŸ Analyse de Sentiment avec DiffÃ©rents ModÃ¨les")

# Barre latÃ©rale
st.sidebar.header("ğŸ› ï¸ ParamÃ¨tres")

# SÃ©lection du modÃ¨le
model_options = ["RÃ©gression Logistique ğŸ“ˆ", "SVM ğŸ¤–", "BERT ğŸ§ ", "XLNET ğŸ”®"]
selected_model = st.sidebar.selectbox("SÃ©lectionnez un modÃ¨le :", model_options)

# Chargement du modÃ¨le
if st.sidebar.button("ğŸ”¬ Charger le modÃ¨le"):
    model, vectorizer, label_encoder = load_model(selected_model)
    if model and vectorizer and label_encoder:
        st.sidebar.success(f"ModÃ¨le {selected_model} chargÃ© avec succÃ¨s ! âœ…")
        st.session_state.model = model
        st.session_state.vectorizer = vectorizer
        st.session_state.label_encoder = label_encoder
    elif model and vectorizer:
        st.sidebar.success(f"ModÃ¨le {selected_model} chargÃ© avec succÃ¨s ! ")
        st.session_state.model = model
        st.session_state.vectorizer = vectorizer
        st.session_state.label_encoder = None
    else:
        st.sidebar.error("âŒ Ã‰chec du chargement du modÃ¨le.")

# Zone principale
st.header("ğŸ” Analyse de Sentiment  ğŸ“Š")
st.markdown('<p class="big-font">Cette application permet de prÃ©dire si un commentaire est <b>positif</b>, <b>nÃ©gatif</b>, ou <b>neutre</b> en fonction du modÃ¨le sÃ©lectionnÃ©. </p>', unsafe_allow_html=True)

# Message initial
st.info("ğŸ‘‹ Bienvenue ! Commencez par charger un modÃ¨le dans la barre latÃ©rale, puis entrez un commentaire pour analyser son sentiment. ğŸ•µï¸â€â™€ï¸")
# Champ de saisie pour le commentaire
user_input = st.text_area("ğŸ“ Entrez un commentaire :", "")

# Bouton de prÃ©diction
if st.button("ğŸš€ PrÃ©dire le sentiment"):
    if "model" in st.session_state and "vectorizer" in st.session_state:
        result = predict_sentiment(user_input, st.session_state.model, st.session_state.vectorizer, st.session_state.label_encoder)
    else:
        st.warning("âš ï¸ Veuillez d'abord charger un modÃ¨le dans la barre latÃ©rale.")